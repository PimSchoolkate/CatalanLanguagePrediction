{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv1D, LeakyReLU, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_data.csv', index_col='Municipality')\n",
    "\n",
    "# Get proper label\n",
    "labels = df.filter(like='catalan')\n",
    "label = df.filter(like='catalan').filter(like='total')\n",
    "\n",
    "data = df.drop(list(labels.columns), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "label[:] = pd.qcut(label['culture_knowledge_of_catalan_total'], q=4, labels=[0,1,2,3])\n",
    "# label[label['culture_knowledge_of_catalan_total'] == 2] = 1\n",
    "# label[label['culture_knowledge_of_catalan_total'] == 3] = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "label_data = pd.get_dummies(label['culture_knowledge_of_catalan_total'])\n",
    "label_data_size = label_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "data = data.drop(['missing_count'], axis=1)\n",
    "data['population_population_by_sex_main'] = pd.Categorical(data['population_population_by_sex_main'])\n",
    "data['population_population_by_sex_main'] = data['population_population_by_sex_main'].cat.codes.astype(float)\n",
    "\n",
    "data['economic_sectors_head_of_livestock_main'] = pd.Categorical(data['economic_sectors_head_of_livestock_main'])\n",
    "data['economic_sectors_head_of_livestock_main'] = data['economic_sectors_head_of_livestock_main'].cat.codes.astype(float)\n",
    "\n",
    "data['economic_sectors_cultivated_land_main'] = pd.Categorical(data['economic_sectors_cultivated_land_main'])\n",
    "data['economic_sectors_cultivated_land_main'] = data['economic_sectors_cultivated_land_main'].cat.codes.astype(float)\n",
    "\n",
    "data['culture_sports_facilities_main'] = pd.Categorical(data['culture_sports_facilities_main'])\n",
    "data['culture_sports_facilities_main'] = data['culture_sports_facilities_main'].cat.codes.astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - x.min()) / (x.max() - x.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    data[col] = normalize(data[col])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(data, label_data, test_size=0.2,random_state=42)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Model, F1score - Val, F1score - train, MASK_ZERO, ALPHA, DROPOUT, LAYERS, BATCH_SIZE]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {'LAYERS': [[1],\n",
    "                     [10],\n",
    "                     [100],\n",
    "                     [100, 10]],\n",
    "          'ALPHA': [0.1,\n",
    "                    0.2,\n",
    "                    0.3,\n",
    "                    0.4],\n",
    "          'DROPOUT': [0.1,\n",
    "                      0.2,\n",
    "                      0.3,\n",
    "                      False],\n",
    "          'BATCH_SIZE': [10,\n",
    "                         20,\n",
    "                         30]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [],
   "source": [
    "DROPOUT = 0.1\n",
    "ALPHA = 0.1\n",
    "LAYERS = [100, 10]\n",
    "BATCH_SIZE = 10\n",
    "INPUT_SHAPE = data.shape[1]\n",
    "\n",
    "def build_model(layers, dropout, alpha):\n",
    "    inpt = Input(shape=INPUT_SHAPE)\n",
    "\n",
    "    x = Flatten()(inpt)\n",
    "\n",
    "    for layer in layers:\n",
    "        x = Dense(layer, activation=LeakyReLU(alpha=alpha))(x)\n",
    "        if dropout != False:\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    out = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inpt, out)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_20 (InputLayer)       [(None, 132)]             0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 132)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 100)               13300     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 4)                 44        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,354\n",
      "Trainable params: 14,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 5ms/step - loss: 1.3379 - accuracy: 0.3431 - val_loss: 1.2692 - val_accuracy: 0.4026\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 1.2043 - accuracy: 0.4276 - val_loss: 1.1986 - val_accuracy: 0.4156\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.1057 - accuracy: 0.4878 - val_loss: 1.1177 - val_accuracy: 0.4805\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.0688 - accuracy: 0.5187 - val_loss: 1.1010 - val_accuracy: 0.5519\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 1.0107 - accuracy: 0.5545 - val_loss: 1.0800 - val_accuracy: 0.5390\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.9923 - accuracy: 0.5724 - val_loss: 1.0685 - val_accuracy: 0.5519\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.5675 - val_loss: 1.0685 - val_accuracy: 0.5325\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.9617 - accuracy: 0.5626 - val_loss: 1.0280 - val_accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.9284 - accuracy: 0.5902 - val_loss: 1.1013 - val_accuracy: 0.4805\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.9365 - accuracy: 0.5805 - val_loss: 0.9890 - val_accuracy: 0.5909\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.8944 - accuracy: 0.5951 - val_loss: 1.0052 - val_accuracy: 0.6299\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.9029 - accuracy: 0.6033 - val_loss: 0.9882 - val_accuracy: 0.6104\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.8818 - accuracy: 0.6309 - val_loss: 0.9770 - val_accuracy: 0.5974\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.8648 - accuracy: 0.6309 - val_loss: 1.0351 - val_accuracy: 0.5779\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.8674 - accuracy: 0.6341 - val_loss: 0.9532 - val_accuracy: 0.6169\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.8618 - accuracy: 0.6195 - val_loss: 1.0090 - val_accuracy: 0.5584\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.8267 - accuracy: 0.6374 - val_loss: 0.9704 - val_accuracy: 0.6039\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.8103 - accuracy: 0.6488 - val_loss: 1.0014 - val_accuracy: 0.5649\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.8239 - accuracy: 0.6293 - val_loss: 1.0391 - val_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.8071 - accuracy: 0.6341 - val_loss: 0.9840 - val_accuracy: 0.6169\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.7849 - accuracy: 0.6846 - val_loss: 0.9333 - val_accuracy: 0.6429\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.7780 - accuracy: 0.6683 - val_loss: 0.9473 - val_accuracy: 0.6234\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.7775 - accuracy: 0.6683 - val_loss: 0.9663 - val_accuracy: 0.5974\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.7707 - accuracy: 0.6846 - val_loss: 0.9448 - val_accuracy: 0.5909\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7434 - accuracy: 0.6878 - val_loss: 0.9166 - val_accuracy: 0.5974\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7541 - accuracy: 0.6569 - val_loss: 0.9264 - val_accuracy: 0.6234\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.7514 - accuracy: 0.6504 - val_loss: 0.9040 - val_accuracy: 0.6169\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.7066 - accuracy: 0.7008 - val_loss: 0.9317 - val_accuracy: 0.5974\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.7123 - accuracy: 0.6797 - val_loss: 0.9368 - val_accuracy: 0.6169\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.7138 - accuracy: 0.6878 - val_loss: 0.9098 - val_accuracy: 0.6169\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.7008 - val_loss: 0.9126 - val_accuracy: 0.6494\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6981 - accuracy: 0.7041 - val_loss: 0.8849 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.7053 - accuracy: 0.6976 - val_loss: 0.9238 - val_accuracy: 0.6104\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.7089 - val_loss: 0.9242 - val_accuracy: 0.5974\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.7154 - val_loss: 0.9043 - val_accuracy: 0.6104\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.7073 - val_loss: 0.8753 - val_accuracy: 0.6429\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6622 - accuracy: 0.7252 - val_loss: 0.9546 - val_accuracy: 0.6299\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.7138 - val_loss: 0.9442 - val_accuracy: 0.6494\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7154 - val_loss: 0.9283 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.7236 - val_loss: 0.9150 - val_accuracy: 0.6494\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.7252 - val_loss: 0.9449 - val_accuracy: 0.6039\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7431 - val_loss: 0.8933 - val_accuracy: 0.6364\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7138 - val_loss: 0.9049 - val_accuracy: 0.6623\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6259 - accuracy: 0.7496 - val_loss: 0.8863 - val_accuracy: 0.6039\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.7382 - val_loss: 0.9107 - val_accuracy: 0.6494\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5884 - accuracy: 0.7480 - val_loss: 1.0007 - val_accuracy: 0.6234\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7593 - val_loss: 1.0272 - val_accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7528 - val_loss: 1.0006 - val_accuracy: 0.6494\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7610 - val_loss: 0.9478 - val_accuracy: 0.6623\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.7772 - val_loss: 0.9410 - val_accuracy: 0.6039\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5598 - accuracy: 0.7577 - val_loss: 0.9276 - val_accuracy: 0.6558\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7756 - val_loss: 0.9011 - val_accuracy: 0.6623\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7447 - val_loss: 0.9277 - val_accuracy: 0.6494\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7740 - val_loss: 0.8802 - val_accuracy: 0.6558\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.7935 - val_loss: 0.9668 - val_accuracy: 0.6494\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7740 - val_loss: 0.9549 - val_accuracy: 0.6623\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.8033 - val_loss: 0.8875 - val_accuracy: 0.6883\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5226 - accuracy: 0.7902 - val_loss: 1.1550 - val_accuracy: 0.5584\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.7772 - val_loss: 0.9265 - val_accuracy: 0.6104\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7870 - val_loss: 0.9744 - val_accuracy: 0.6494\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4725 - accuracy: 0.8065 - val_loss: 0.9960 - val_accuracy: 0.6494\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7854 - val_loss: 0.9466 - val_accuracy: 0.6299\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.8049 - val_loss: 0.9208 - val_accuracy: 0.6558\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4745 - accuracy: 0.7967 - val_loss: 0.9428 - val_accuracy: 0.6494\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4956 - accuracy: 0.7821 - val_loss: 0.9850 - val_accuracy: 0.6299\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4735 - accuracy: 0.7967 - val_loss: 0.9403 - val_accuracy: 0.6623\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8276 - val_loss: 0.9898 - val_accuracy: 0.6818\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4734 - accuracy: 0.7886 - val_loss: 0.9754 - val_accuracy: 0.6364\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.8098 - val_loss: 0.9449 - val_accuracy: 0.6494\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8211 - val_loss: 0.9872 - val_accuracy: 0.6364\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8179 - val_loss: 0.9069 - val_accuracy: 0.6883\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.8146 - val_loss: 0.9734 - val_accuracy: 0.6494\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8195 - val_loss: 0.9610 - val_accuracy: 0.6558\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.8293 - val_loss: 1.1930 - val_accuracy: 0.6234\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8065 - val_loss: 1.0121 - val_accuracy: 0.6104\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8016 - val_loss: 0.9992 - val_accuracy: 0.6429\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8179 - val_loss: 0.9732 - val_accuracy: 0.6234\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8293 - val_loss: 1.0003 - val_accuracy: 0.6688\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8293 - val_loss: 0.9389 - val_accuracy: 0.6883\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3831 - accuracy: 0.8439 - val_loss: 1.0382 - val_accuracy: 0.6039\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8439 - val_loss: 1.0302 - val_accuracy: 0.6558\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3453 - accuracy: 0.8504 - val_loss: 1.0545 - val_accuracy: 0.6688\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8650 - val_loss: 1.0849 - val_accuracy: 0.6104\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8455 - val_loss: 1.0826 - val_accuracy: 0.6429\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8455 - val_loss: 1.0271 - val_accuracy: 0.6364\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8260 - val_loss: 1.0552 - val_accuracy: 0.6558\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.8618 - val_loss: 1.0630 - val_accuracy: 0.6169\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3441 - accuracy: 0.8569 - val_loss: 1.0129 - val_accuracy: 0.6688\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3230 - accuracy: 0.8683 - val_loss: 1.0158 - val_accuracy: 0.6169\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3582 - accuracy: 0.8602 - val_loss: 1.2612 - val_accuracy: 0.6234\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8390 - val_loss: 1.0246 - val_accuracy: 0.6429\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3189 - accuracy: 0.8748 - val_loss: 1.0805 - val_accuracy: 0.5974\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.8488 - val_loss: 1.0716 - val_accuracy: 0.6429\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3133 - accuracy: 0.8878 - val_loss: 1.0958 - val_accuracy: 0.6623\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3133 - accuracy: 0.8748 - val_loss: 1.2547 - val_accuracy: 0.6558\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3122 - accuracy: 0.8764 - val_loss: 1.1428 - val_accuracy: 0.5974\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8472 - val_loss: 1.1693 - val_accuracy: 0.6364\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3587 - accuracy: 0.8504 - val_loss: 1.0761 - val_accuracy: 0.6429\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.8602 - val_loss: 1.0260 - val_accuracy: 0.6494\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.3073 - accuracy: 0.8764 - val_loss: 1.0864 - val_accuracy: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d36b6343a0>"
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = build_model(LAYERS, DROPOUT, ALPHA)\n",
    "m.summary()\n",
    "m.fit(train_x, train_y, batch_size=BATCH_SIZE, validation_data=(val_x,val_y), epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(alpha=0,\n",
    "                           activation='logistic', max_iter=1000,\n",
    "                           solver='adam',random_state=42)\n",
    "mlp.fit(train_x,train_y)\n",
    "y_pred = mlp.predict(val_x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "def confusion_matrix(pred, true):\n",
    "    pred = pd.Series(np.argmax(pred, axis=1))\n",
    "    true = pd.Series(true.columns[np.where(true!=0)[1]])\n",
    "\n",
    "    true.name = 'target'\n",
    "    pred.name = 'predicted'\n",
    "    cm = pd.crosstab(true.reset_index(drop=True), pred.reset_index(drop=True))\n",
    "    cm = cm[cm.index]\n",
    "    return cm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[1, 2] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[1;32mIn [303]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mconfusion_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [301]\u001B[0m, in \u001B[0;36mconfusion_matrix\u001B[1;34m(pred, true)\u001B[0m\n\u001B[0;32m      6\u001B[0m pred\u001B[38;5;241m.\u001B[39mname \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpredicted\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      7\u001B[0m cm \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mcrosstab(true\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), pred\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m----> 8\u001B[0m cm \u001B[38;5;241m=\u001B[39m \u001B[43mcm\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cm\n",
      "File \u001B[1;32m~\\.virtualenvs\\CatalanLanguagePrediction\\lib\\site-packages\\pandas\\core\\frame.py:3464\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3462\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[0;32m   3463\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 3464\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   3466\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[0;32m   3467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[1;32m~\\.virtualenvs\\CatalanLanguagePrediction\\lib\\site-packages\\pandas\\core\\indexing.py:1314\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1311\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1312\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m ax\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 1314\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_read_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m needs_i8_conversion(ax\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\n\u001B[0;32m   1317\u001B[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001B[0;32m   1318\u001B[0m ):\n\u001B[0;32m   1319\u001B[0m     \u001B[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001B[39;00m\n\u001B[0;32m   1320\u001B[0m     \u001B[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001B[39;00m\n\u001B[0;32m   1321\u001B[0m     keyarr \u001B[38;5;241m=\u001B[39m ax\u001B[38;5;241m.\u001B[39mtake(indexer)\n",
      "File \u001B[1;32m~\\.virtualenvs\\CatalanLanguagePrediction\\lib\\site-packages\\pandas\\core\\indexing.py:1377\u001B[0m, in \u001B[0;36m_LocIndexer._validate_read_indexer\u001B[1;34m(self, key, indexer, axis)\u001B[0m\n\u001B[0;32m   1374\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1376\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 1377\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[1, 2] not in index'"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_pred, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.74509804, 0.4691358 , 0.45360825, 0.73584906])"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.Series(np.argmax(m.predict(test_x), axis=1))\n",
    "true = pd.Series(test_y.columns[np.where(test_y!=0)[1]])\n",
    "f1_score(list(true.values), list(pred.values), average=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}